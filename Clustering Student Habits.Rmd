---
title: "Clustering Students Habits"
author: "Shervairus_Morris"
date: "2025-05-14"
output: html_document
---

## Introduction

This document explores potential clusters of students based on their study habits, lifestyle factors, and mental health using the "Student Habits vs Academic Performance" dataset.

## Loading Libraries and Data

First, we load the necessary libraries and the dataset.

```{r}
library(tidyverse)
screen_time <- read_csv("data/student_habits_performance.csv")
```

```{r}
head(screen_time)
```

## Data Structure

Let's examine the structure of the dataset using the `str()` function to understand the data types of each column.

```{r}
str(screen_time)
```

## Summary Statistics

We'll also use the `summary()` function to get descriptive statistics for the numeric variables and frequency counts for the categorical ones.

```{r}
summary(screen_time)
```

## Check for Missing Data

Next I will check the data set for any missing values. I will use the 'colSum()' function.

```{r}
colSums(is.na(screen_time))
```

## Notes on Initial Data Exploration

The dataset includes 1000 student records with 16 variables. We identified nine numeric variables (`age`, `study_hours_per_day`, `social_media_hours`, `netflix_hours`, `attendance_percentage`, `sleep_hours`, `exercise_frequency`, `mental_health_rating`, `exam_score`) and seven categorical variables (`student_id`, `gender`, `part_time_job`, `diet_quality`, `parental_education_level`, `internet_quality`, `extracurricular_participation`). The data types appear appropriate.

The summary statistics for the numeric variables reveal the following ranges and central tendencies:

-   **Age:** Ranges from 17 to 24 (mean: 20.50, median: 20.00).
-   **Study Hours:** Ranges from 0.0 to 8.3 (mean: 3.55, median: 3.50).
-   **Social Media Hours:** Ranges from 0.0 to 7.2 (mean: 2.51, median: 2.50).
-   **Netflix Hours:** Ranges from 0.0 to 5.4 (mean: 1.82, median: 1.80).
-   **Attendance:** Ranges from 56.0 to 100.0 (mean: 84.13, median: 84.40).
-   **Sleep Hours:** Ranges from 3.2 to 10.0 (mean: 6.47, median: 6.50).
-   **Exercise Frequency:** Ranges from 0.0 to 6.0 (mean: 3.04, median: 3.00).
-   **Mental Health Rating:** Ranges from 1.0 to 10.0 (mean: 5.44, median: 5.00).
-   **Exam Score:** Ranges from 18.4 to 100.0 (mean: 69.60, median: 70.50).

The `diet_quality` variable includes categories: Fair (326), Good (345), Poor (329). The other categorical variables will require further exploration to understand their distributions fully.

## Isolate Numeric Variables for clustering

I will create a new data frame that will contain the numerical variables. I plan on using Principle Competent Analysis for this data set. I will go into further detail in a later step.

```{r}
numerical_data<-screen_time %>%
  select(study_hours_per_day, social_media_hours, netflix_hours,
         sleep_hours, exercise_frequency, mental_health_rating)

print(numerical_data)

```

# Scale Numerical Data

```{r}
scaled_data<-scale(numerical_data)
scaled_data<-as.data.frame(numerical_data)
head(numerical_data)
```

## Visualize Distrubtion of Data

```{r}
library(ggplot2)
library(tidyr)

# Prepare the data for plotting distributions
distributions_data <- scaled_data %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

# Create the histograms
ggplot(distributions_data, aes(x = Value)) +
  geom_histogram(fill = "skyblue", color = "black") +
  facet_wrap(~ Variable, scales = "free") +
  labs(
    title = "Distributions of Variables for Clustering",
    x = "Value",
    y = "Frequency"
  ) +
  theme_minimal()
```

## Checking for Multicollinearity

After examining the histograms of the numeric variables, we observed the distributions of study hours, social media hours, and Netflix hours appeared to be somewhat right-skewed, suggesting that some students engage in these activities more than others. Additionally, variables like sleep hours and mental health rating showed more central tendencies. While the histograms provide insights into the individual distributions, they don't directly reveal the relationships *between* these variables.

Given that K-Means clustering relies on distance metrics, and highly correlated variables could disproportionately influence these distances, I decided to check for multicollinearity among our numeric variables before proceeding with the Elbow Method and the K-Means algorithm. High multicollinearity could indicate redundancy in our features, where some variables are essentially measuring the same underlying construct. Addressing this could lead to more stable and interpretable clusters.

I will use the Variance Inflation Factor (VIF) to assess the degree of multicollinearity.

```{r}
library(car)

# Calculate Variance Inflation Factors (VIF) for the original, unscaled numeric variables
vif_values <- vif(lm(study_hours_per_day ~ social_media_hours + netflix_hours +
                       sleep_hours + exercise_frequency + mental_health_rating,
                     data = screen_time))

# Print the VIF values
print(vif_values)
```

The Variance Inflation Factors for all six of our chosen numeric variables are extremely low (very close to 1). This definitively indicates that there is no significant multicollinearity among these variables in the original dataset. Each variable's variance is not inflated by the presence of the others, meaning they are largely independent of each other in terms of linear relationships.

#Principle Competent Analysis (PCA)
```{r}
# Perform PCA on the scaled data
pca_result <- prcomp(scaled_data, scale. = FALSE) # scale. = FALSE since data is already scaled

# Examine the explained variance
print(summary(pca_result))
```
The table of my components shows that the first 4 principle competent make up 85% of the variance of my data.

##Determining Cutoff for K-Means Clustering
I will use the elbow method to determining the optimal number of clusters. I will use the 'fviz_nbclust()' function along with the kmeans clustering method to generate the elbow plot. 
```{r}

library(factoextra)
set.seed(1234) #for  reproducibility
fviz_nbclust(scaled_data, kmeans, method = "wss") +
  labs(title = "Elbow Method for Optimal k") +
  theme_minimal()
```
the "elbow" appears to be around k=4. This suggests that using 4 clusters might be a good choice for our K-Means algorithm. Now i will move to the clusting. For this project I will be using K-Means clustering.
```{r}
set.seed(123) 
# Create a data frame with the principal components
pca_df <- as.data.frame(pca_result$x[, 1:4])
# --- K-Means on First Four Principal Components ---
kmeans_pca_result <- kmeans(pca_df, centers = 4, nstart = 10) 

# Add cluster assignments back to a dataframe that includes the first two PCs for visualization
pca_df_clustered <- as.data.frame(pca_result$x[, 1:2]) %>%
  mutate(cluster = factor(kmeans_pca_result$cluster))

# --- Visualize Clusters in PCA Space (using the first two PCs for the plot) ---
fviz_cluster(kmeans_pca_result, data = as.data.frame(pca_result$x[, 1:2]),
             ellipse.type = "t",
             geom = "point",
             pointsize = 3,
             palette = "jco",
             ggtheme = theme_minimal(),
             main = "K-Means Clusters (based on 4 PCs) Visualized in PC1 & PC2")

```

```{r}
# Examine the cluster centroids in the PCA space (first four components)
print(kmeans_pca_result$centers)

# Examine the loadings of the principal components
print(pca_result$rotation)
```
# Key Insights
Cluster 1 (Blue Circles - Top Left): The "Healthy and Engaged" Students: These students tend to have higher mental health ratings and higher exercise frequency. They also potentially have higher study hours and more sleep.

Cluster 2 (Yellow Triangles - Bottom Right): The "Potentially Stressed and Less Active" Students: These students tend to have lower mental health ratings and lower exercise frequency. They also potentially have higher study hours and more sleep.

Cluster 3 (Gray Squares - Bottom Left): The "Potentially Less Active but Positive" Students: These students tend to have higher mental health ratings but lower exercise frequency. They also potentially have lower study hours and less sleep.

Cluster 4 (Red Crosses - Top Right): The "Active but Potentially Stressed" Students: These students tend to have lower mental health ratings but higher exercise frequency. They also potentially have lower study hours and less sleep.

# Summary of Findings
I started by exploring the distributions of the numeric variables. Then scaled the data and used the Elbow Method to help us determine a suitable number of clusters. I performed PCA to reduce dimensionality and visualize the clusters, deciding to cluster on the first four principal components which captured a significant amount of variance. The resulting four clusters show distinct patterns in terms of mental health, exercise frequency, and potentially study and sleep habits.
